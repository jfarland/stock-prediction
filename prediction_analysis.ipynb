{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction Performance Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis of your stock prediction model's performance across different stocks, time periods, and confidence levels.\n",
    "\n",
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"üìä Stock Prediction Analysis Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Prediction Data\n",
    "\n",
    "Load prediction results from your deployed service or local experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prediction_files(prediction_dir=\"./predictions\"):\n",
    "    \"\"\"\n",
    "    Load all prediction files from directory\n",
    "    \"\"\"\n",
    "    prediction_files = glob.glob(f\"{prediction_dir}/predictions_*.json\")\n",
    "    \n",
    "    if not prediction_files:\n",
    "        print(f\"‚ùå No prediction files found in {prediction_dir}\")\n",
    "        print(\"üí° Tip: If running from local experiments, check if files are in current directory\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    for file_path in sorted(prediction_files):\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                predictions = json.load(f)\n",
    "            \n",
    "            # Convert to DataFrame and add file info\n",
    "            df = pd.DataFrame(predictions)\n",
    "            df['source_file'] = file_path\n",
    "            all_predictions.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error loading {file_path}: {e}\")\n",
    "    \n",
    "    if all_predictions:\n",
    "        combined_df = pd.concat(all_predictions, ignore_index=True)\n",
    "        print(f\"‚úÖ Loaded {len(combined_df)} predictions from {len(prediction_files)} files\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_sample_results():\n",
    "    \"\"\"\n",
    "    Create sample prediction results for demonstration\n",
    "    Replace this with your actual prediction loading\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'JPM', 'V', 'PG']\n",
    "    dates = pd.date_range('2024-01-01', '2024-03-01', freq='B')  # Business days only\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for date in dates:\n",
    "        for ticker in tickers:\n",
    "            # Simulate predictions with realistic patterns\n",
    "            base_accuracy = np.random.uniform(0.45, 0.65)  # Stock-specific performance\n",
    "            confidence = np.random.uniform(0.5, 0.95)\n",
    "            \n",
    "            # Higher confidence should correlate with better accuracy\n",
    "            if confidence > 0.8:\n",
    "                prediction_correct = np.random.random() < (base_accuracy + 0.1)\n",
    "            elif confidence > 0.6:\n",
    "                prediction_correct = np.random.random() < base_accuracy\n",
    "            else:\n",
    "                prediction_correct = np.random.random() < (base_accuracy - 0.05)\n",
    "            \n",
    "            prediction = np.random.choice([0, 1])\n",
    "            actual = prediction if prediction_correct else (1 - prediction)\n",
    "            \n",
    "            predictions.append({\n",
    "                'ticker': ticker,\n",
    "                'prediction_date': date.strftime('%Y-%m-%d'),\n",
    "                'target_date': (date + timedelta(days=1)).strftime('%Y-%m-%d'),\n",
    "                'prediction': prediction,\n",
    "                'actual': actual,\n",
    "                'confidence': confidence,\n",
    "                'correct': prediction == actual,\n",
    "                'latest_close': np.random.uniform(100, 300)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "# Try to load actual prediction files, fall back to sample data\n",
    "predictions_df = load_prediction_files()\n",
    "\n",
    "if predictions_df.empty:\n",
    "    print(\"üìù Using sample data for demonstration\")\n",
    "    predictions_df = load_sample_results()\n",
    "\n",
    "# Convert date columns\n",
    "predictions_df['prediction_date'] = pd.to_datetime(predictions_df['prediction_date'])\n",
    "predictions_df['target_date'] = pd.to_datetime(predictions_df['target_date'])\n",
    "\n",
    "print(f\"\\nüìä Dataset Overview:\")\n",
    "print(f\"   Total Predictions: {len(predictions_df):,}\")\n",
    "print(f\"   Date Range: {predictions_df['prediction_date'].min().date()} to {predictions_df['prediction_date'].max().date()}\")\n",
    "print(f\"   Unique Stocks: {predictions_df['ticker'].nunique()}\")\n",
    "print(f\"   Overall Accuracy: {predictions_df['correct'].mean():.1%}\")\n",
    "\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Actual Market Data for Verification\n",
    "\n",
    "Download actual stock prices to verify prediction accuracy and calculate real returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_actual_market_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Download actual market data to verify predictions\n",
    "    \"\"\"\n",
    "    print(f\"üì• Downloading actual market data for {len(tickers)} stocks...\")\n",
    "    \n",
    "    market_data = {}\n",
    "    failed_tickers = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            hist = stock.history(start=start_date, end=end_date)\n",
    "            \n",
    "            if not hist.empty:\n",
    "                market_data[ticker] = hist\n",
    "                print(f\"‚úì {ticker}: {len(hist)} days\")\n",
    "            else:\n",
    "                failed_tickers.append(ticker)\n",
    "                \n",
    "        except Exception as e:\n",
    "            failed_tickers.append(ticker)\n",
    "            print(f\"‚úó {ticker}: {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Downloaded data for {len(market_data)}/{len(tickers)} stocks\")\n",
    "    if failed_tickers:\n",
    "        print(f\"‚ùå Failed: {failed_tickers}\")\n",
    "    \n",
    "    return market_data\n",
    "\n",
    "def verify_predictions_with_actual_data(predictions_df, market_data):\n",
    "    \"\"\"\n",
    "    Verify predictions against actual market data\n",
    "    \"\"\"\n",
    "    verified_predictions = []\n",
    "    \n",
    "    for _, row in predictions_df.iterrows():\n",
    "        ticker = row['ticker']\n",
    "        target_date = row['target_date']\n",
    "        \n",
    "        if ticker in market_data:\n",
    "            stock_data = market_data[ticker]\n",
    "            \n",
    "            # Find the target trading day (handle weekends/holidays)\n",
    "            target_dates = pd.date_range(target_date, target_date + timedelta(days=3), freq='B')\n",
    "            \n",
    "            for check_date in target_dates:\n",
    "                if check_date.date() in stock_data.index.date:\n",
    "                    day_data = stock_data.loc[stock_data.index.date == check_date.date()].iloc[0]\n",
    "                    \n",
    "                    # Calculate actual direction and return\n",
    "                    actual_direction = 1 if day_data['Close'] > day_data['Open'] else 0\n",
    "                    actual_return = (day_data['Close'] - day_data['Open']) / day_data['Open']\n",
    "                    \n",
    "                    # Update prediction record\n",
    "                    verified_row = row.copy()\n",
    "                    verified_row['actual_verified'] = actual_direction\n",
    "                    verified_row['actual_return'] = actual_return\n",
    "                    verified_row['correct_verified'] = (row['prediction'] == actual_direction)\n",
    "                    verified_row['actual_open'] = day_data['Open']\n",
    "                    verified_row['actual_close'] = day_data['Close']\n",
    "                    verified_row['actual_volume'] = day_data['Volume']\n",
    "                    \n",
    "                    verified_predictions.append(verified_row)\n",
    "                    break\n",
    "    \n",
    "    return pd.DataFrame(verified_predictions)\n",
    "\n",
    "# Download actual market data for verification\n",
    "unique_tickers = predictions_df['ticker'].unique()\n",
    "start_date = predictions_df['target_date'].min() - timedelta(days=5)\n",
    "end_date = predictions_df['target_date'].max() + timedelta(days=5)\n",
    "\n",
    "market_data = download_actual_market_data(unique_tickers, start_date, end_date)\n",
    "\n",
    "# Verify predictions (only if we have real market data)\n",
    "if market_data:\n",
    "    verified_df = verify_predictions_with_actual_data(predictions_df, market_data)\n",
    "    \n",
    "    if not verified_df.empty:\n",
    "        print(f\"\\nüîç Verification Results:\")\n",
    "        print(f\"   Verified Predictions: {len(verified_df):,}\")\n",
    "        print(f\"   Verified Accuracy: {verified_df['correct_verified'].mean():.1%}\")\n",
    "        \n",
    "        # Use verified data if available\n",
    "        if 'actual_verified' in verified_df.columns:\n",
    "            predictions_df = verified_df\n",
    "            predictions_df['actual'] = predictions_df['actual_verified']\n",
    "            predictions_df['correct'] = predictions_df['correct_verified']\n",
    "else:\n",
    "    print(\"üìä Using original prediction data (no market data verification)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Overall Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_overall_performance(df):\n",
    "    \"\"\"\n",
    "    Comprehensive overall performance analysis\n",
    "    \"\"\"\n",
    "    print(\"üéØ OVERALL MODEL PERFORMANCE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    total_predictions = len(df)\n",
    "    overall_accuracy = df['correct'].mean()\n",
    "    \n",
    "    # Basic metrics\n",
    "    print(f\"üìä Basic Metrics:\")\n",
    "    print(f\"   Total Predictions: {total_predictions:,}\")\n",
    "    print(f\"   Overall Accuracy: {overall_accuracy:.1%}\")\n",
    "    print(f\"   Improvement over Random: {(overall_accuracy - 0.5) * 100:+.1f} percentage points\")\n",
    "    \n",
    "    # Statistical significance\n",
    "    from scipy.stats import binomtest\n",
    "    p_value = binomtest(df['correct'].sum(), total_predictions, 0.5).pvalue\n",
    "    is_significant = p_value < 0.05\n",
    "    \n",
    "    print(f\"\\nüìà Statistical Analysis:\")\n",
    "    print(f\"   P-value vs Random: {p_value:.4f}\")\n",
    "    print(f\"   Statistically Significant: {'‚úÖ YES' if is_significant else '‚ùå NO'}\")\n",
    "    \n",
    "    # Precision, Recall, F1\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    precision = precision_score(df['actual'], df['prediction'])\n",
    "    recall = recall_score(df['actual'], df['prediction'])\n",
    "    f1 = f1_score(df['actual'], df['prediction'])\n",
    "    \n",
    "    print(f\"\\nüéØ Classification Metrics:\")\n",
    "    print(f\"   Precision: {precision:.3f}\")\n",
    "    print(f\"   Recall: {recall:.3f}\")\n",
    "    print(f\"   F1-Score: {f1:.3f}\")\n",
    "    \n",
    "    # Prediction distribution\n",
    "    up_predictions = (df['prediction'] == 1).sum()\n",
    "    down_predictions = (df['prediction'] == 0).sum()\n",
    "    actual_up = (df['actual'] == 1).sum()\n",
    "    actual_down = (df['actual'] == 0).sum()\n",
    "    \n",
    "    print(f\"\\nüìä Prediction Distribution:\")\n",
    "    print(f\"   Predicted UP: {up_predictions:,} ({up_predictions/total_predictions:.1%})\")\n",
    "    print(f\"   Predicted DOWN: {down_predictions:,} ({down_predictions/total_predictions:.1%})\")\n",
    "    print(f\"   Actual UP: {actual_up:,} ({actual_up/total_predictions:.1%})\")\n",
    "    print(f\"   Actual DOWN: {actual_down:,} ({actual_down/total_predictions:.1%})\")\n",
    "    \n",
    "    # Confidence analysis\n",
    "    avg_confidence = df['confidence'].mean()\n",
    "    high_conf_mask = df['confidence'] >= 0.7\n",
    "    high_conf_accuracy = df[high_conf_mask]['correct'].mean() if high_conf_mask.sum() > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüéØ Confidence Analysis:\")\n",
    "    print(f\"   Average Confidence: {avg_confidence:.3f}\")\n",
    "    print(f\"   High Confidence (‚â•0.7) Predictions: {high_conf_mask.sum():,} ({high_conf_mask.sum()/total_predictions:.1%})\")\n",
    "    print(f\"   High Confidence Accuracy: {high_conf_accuracy:.1%}\")\n",
    "    \n",
    "    return {\n",
    "        'total_predictions': total_predictions,\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'p_value': p_value,\n",
    "        'is_significant': is_significant,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'high_confidence_accuracy': high_conf_accuracy\n",
    "    }\n",
    "\n",
    "overall_metrics = analyze_overall_performance(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance by Individual Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_stock_performance(df):\n",
    "    \"\"\"\n",
    "    Analyze performance for each individual stock\n",
    "    \"\"\"\n",
    "    stock_metrics = []\n",
    "    \n",
    "    for ticker in df['ticker'].unique():\n",
    "        stock_data = df[df['ticker'] == ticker]\n",
    "        \n",
    "        if len(stock_data) < 5:  # Skip stocks with too few predictions\n",
    "            continue\n",
    "        \n",
    "        accuracy = stock_data['correct'].mean()\n",
    "        total_preds = len(stock_data)\n",
    "        avg_confidence = stock_data['confidence'].mean()\n",
    "        \n",
    "        # Separate accuracy for UP vs DOWN predictions\n",
    "        up_preds = stock_data[stock_data['prediction'] == 1]\n",
    "        down_preds = stock_data[stock_data['prediction'] == 0]\n",
    "        \n",
    "        up_accuracy = up_preds['correct'].mean() if len(up_preds) > 0 else 0\n",
    "        down_accuracy = down_preds['correct'].mean() if len(down_preds) > 0 else 0\n",
    "        \n",
    "        # Prediction bias\n",
    "        up_prediction_rate = (stock_data['prediction'] == 1).mean()\n",
    "        actual_up_rate = (stock_data['actual'] == 1).mean()\n",
    "        prediction_bias = up_prediction_rate - actual_up_rate\n",
    "        \n",
    "        # High confidence performance\n",
    "        high_conf_data = stock_data[stock_data['confidence'] >= 0.7]\n",
    "        high_conf_accuracy = high_conf_data['correct'].mean() if len(high_conf_data) > 0 else accuracy\n",
    "        \n",
    "        stock_metrics.append({\n",
    "            'ticker': ticker,\n",
    "            'accuracy': accuracy,\n",
    "            'total_predictions': total_preds,\n",
    "            'avg_confidence': avg_confidence,\n",
    "            'up_accuracy': up_accuracy,\n",
    "            'down_accuracy': down_accuracy,\n",
    "            'up_prediction_rate': up_prediction_rate,\n",
    "            'actual_up_rate': actual_up_rate,\n",
    "            'prediction_bias': prediction_bias,\n",
    "            'high_conf_accuracy': high_conf_accuracy,\n",
    "            'high_conf_count': len(high_conf_data)\n",
    "        })\n",
    "    \n",
    "    stock_df = pd.DataFrame(stock_metrics).sort_values('accuracy', ascending=False)\n",
    "    \n",
    "    print(\"üìà STOCK-BY-STOCK PERFORMANCE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nüèÜ TOP 10 PERFORMING STOCKS:\")\n",
    "    for i, (_, row) in enumerate(stock_df.head(10).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['ticker']:5s} - {row['accuracy']:.1%} accuracy ({row['total_predictions']:3d} predictions, {row['avg_confidence']:.2f} avg conf)\")\n",
    "    \n",
    "    print(f\"\\nüìâ BOTTOM 5 PERFORMING STOCKS:\")\n",
    "    for i, (_, row) in enumerate(stock_df.tail(5).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['ticker']:5s} - {row['accuracy']:.1%} accuracy ({row['total_predictions']:3d} predictions, {row['avg_confidence']:.2f} avg conf)\")\n",
    "    \n",
    "    # Performance categories\n",
    "    excellent = stock_df[stock_df['accuracy'] > 0.65]\n",
    "    good = stock_df[(stock_df['accuracy'] > 0.55) & (stock_df['accuracy'] <= 0.65)]\n",
    "    average = stock_df[(stock_df['accuracy'] > 0.45) & (stock_df['accuracy'] <= 0.55)]\n",
    "    poor = stock_df[stock_df['accuracy'] <= 0.45]\n",
    "    \n",
    "    print(f\"\\nüìä PERFORMANCE CATEGORIES:\")\n",
    "    print(f\"   Excellent (>65%): {len(excellent)} stocks\")\n",
    "    print(f\"   Good (55-65%): {len(good)} stocks\")\n",
    "    print(f\"   Average (45-55%): {len(average)} stocks\")\n",
    "    print(f\"   Poor (<45%): {len(poor)} stocks\")\n",
    "    \n",
    "    if len(poor) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Consider excluding poor performers: {', '.join(poor['ticker'].tolist())}\")\n",
    "    \n",
    "    return stock_df\n",
    "\n",
    "stock_performance = analyze_stock_performance(predictions_df)\n",
    "stock_performance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization: Stock Performance Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock Performance Bar Chart\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Sort stocks by accuracy for better visualization\n",
    "stock_sorted = stock_performance.sort_values('accuracy', ascending=True)\n",
    "\n",
    "# Color code based on performance\n",
    "colors = ['red' if x < 0.45 else 'orange' if x < 0.5 else 'lightblue' if x < 0.55 else 'lightgreen' if x < 0.65 else 'green' \n",
    "          for x in stock_sorted['accuracy']]\n",
    "\n",
    "# Create horizontal bar chart\n",
    "bars = plt.barh(range(len(stock_sorted)), stock_sorted['accuracy'], color=colors, alpha=0.7)\n",
    "\n",
    "# Add reference lines\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "plt.axvline(x=0.55, color='blue', linestyle='--', alpha=0.5, label='Good (55%)')\n",
    "plt.axvline(x=0.65, color='green', linestyle='--', alpha=0.5, label='Excellent (65%)')\n",
    "\n",
    "# Customize chart\n",
    "plt.yticks(range(len(stock_sorted)), stock_sorted['ticker'])\n",
    "plt.xlabel('Prediction Accuracy')\n",
    "plt.title('Stock Prediction Accuracy by Ticker\\n(Higher is Better)', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add accuracy labels on bars\n",
    "for i, (bar, accuracy) in enumerate(zip(bars, stock_sorted['accuracy'])):\n",
    "    plt.text(accuracy + 0.005, i, f'{accuracy:.1%}', \n",
    "             va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìä Stock Performance Summary:\")\n",
    "print(f\"   Best Performing Stock: {stock_performance.iloc[0]['ticker']} ({stock_performance.iloc[0]['accuracy']:.1%})\")\n",
    "print(f\"   Worst Performing Stock: {stock_performance.iloc[-1]['ticker']} ({stock_performance.iloc[-1]['accuracy']:.1%})\")\n",
    "print(f\"   Average Accuracy Across Stocks: {stock_performance['accuracy'].mean():.1%}\")\n",
    "print(f\"   Standard Deviation: {stock_performance['accuracy'].std():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temporal Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_temporal_performance(df):\n",
    "    \"\"\"\n",
    "    Analyze how performance changes over time\n",
    "    \"\"\"\n",
    "    # Daily performance\n",
    "    daily_performance = df.groupby('prediction_date').agg({\n",
    "        'correct': ['mean', 'count'],\n",
    "        'confidence': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    daily_performance.columns = ['accuracy', 'prediction_count', 'avg_confidence']\n",
    "    daily_performance = daily_performance.reset_index()\n",
    "    \n",
    "    # Weekly performance\n",
    "    df['week'] = df['prediction_date'].dt.isocalendar().week\n",
    "    weekly_performance = df.groupby('week')['correct'].mean().reset_index()\n",
    "    \n",
    "    # Day of week performance\n",
    "    df['day_of_week'] = df['prediction_date'].dt.day_name()\n",
    "    dow_performance = df.groupby('day_of_week')['correct'].agg(['mean', 'count']).round(3)\n",
    "    \n",
    "    print(\"üìÖ TEMPORAL PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nüìä Performance by Day of Week:\")\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "    for day in day_order:\n",
    "        if day in dow_performance.index:\n",
    "            row = dow_performance.loc[day]\n",
    "            print(f\"   {day:10s}: {row['mean']:.1%} accuracy ({int(row['count']):3d} predictions)\")\n",
    "    \n",
    "    # Best and worst days\n",
    "    best_days = daily_performance.nlargest(5, 'accuracy')\n",
    "    worst_days = daily_performance.nsmallest(5, 'accuracy')\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Performing Days:\")\n",
    "    for _, day in best_days.iterrows():\n",
    "        print(f\"   {day['prediction_date'].strftime('%Y-%m-%d')}: {day['accuracy']:.1%} ({day['prediction_count']} predictions)\")\n",
    "    \n",
    "    print(f\"\\nüìâ Worst Performing Days:\")\n",
    "    for _, day in worst_days.iterrows():\n",
    "        print(f\"   {day['prediction_date'].strftime('%Y-%m-%d')}: {day['accuracy']:.1%} ({day['prediction_count']} predictions)\")\n",
    "    \n",
    "    return daily_performance, weekly_performance, dow_performance\n",
    "\n",
    "daily_perf, weekly_perf, dow_perf = analyze_temporal_performance(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temporal performance\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Daily accuracy over time\n",
    "ax1.plot(daily_perf['prediction_date'], daily_perf['accuracy'], marker='o', linewidth=2, markersize=4)\n",
    "ax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "ax1.axhline(y=daily_perf['accuracy'].mean(), color='blue', linestyle='--', alpha=0.7, label=f'Average ({daily_perf[\"accuracy\"].mean():.1%})')\n",
    "ax1.set_title('Daily Prediction Accuracy Over Time')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Day of week performance\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "dow_data = [dow_perf.loc[day, 'mean'] if day in dow_perf.index else 0 for day in day_order]\n",
    "dow_colors = ['lightgreen' if x > 0.5 else 'lightcoral' for x in dow_data]\n",
    "\n",
    "bars = ax2.bar(day_order, dow_data, color=dow_colors, alpha=0.7)\n",
    "ax2.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "ax2.set_title('Accuracy by Day of Week')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add accuracy labels on bars\n",
    "for bar, accuracy in zip(bars, dow_data):\n",
    "    if accuracy > 0:\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "                f'{accuracy:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Confidence vs Accuracy Scatter\n",
    "ax3.scatter(predictions_df['confidence'], predictions_df['correct'], alpha=0.5, s=10)\n",
    "\n",
    "# Add trend line\n",
    "confidence_bins = np.arange(0.5, 1.0, 0.05)\n",
    "bin_centers = []\n",
    "bin_accuracies = []\n",
    "\n",
    "for i in range(len(confidence_bins)-1):\n",
    "    mask = (predictions_df['confidence'] >= confidence_bins[i]) & (predictions_df['confidence'] < confidence_bins[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        bin_centers.append((confidence_bins[i] + confidence_bins[i+1]) / 2)\n",
    "        bin_accuracies.append(predictions_df[mask]['correct'].mean())\n",
    "\n",
    "if bin_centers:\n",
    "    ax3.plot(bin_centers, bin_accuracies, color='red', linewidth=3, marker='o', label='Binned Average')\n",
    "\n",
    "ax3.axhline(y=0.5, color='black', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "ax3.set_xlabel('Prediction Confidence')\n",
    "ax3.set_ylabel('Actual Accuracy (0=Wrong, 1=Correct)')\n",
    "ax3.set_title('Model Calibration: Confidence vs Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prediction count over time\n",
    "ax4.bar(daily_perf['prediction_date'], daily_perf['prediction_count'], alpha=0.7, color='skyblue')\n",
    "ax4.set_title('Number of Predictions Per Day')\n",
    "ax4.set_ylabel('Prediction Count')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confidence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_confidence_patterns(df):\n",
    "    \"\"\"\n",
    "    Detailed analysis of confidence score patterns\n",
    "    \"\"\"\n",
    "    print(\"üéØ CONFIDENCE ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Confidence distribution\n",
    "    conf_stats = df['confidence'].describe()\n",
    "    print(f\"\\nüìä Confidence Distribution:\")\n",
    "    print(f\"   Mean: {conf_stats['mean']:.3f}\")\n",
    "    print(f\"   Median: {conf_stats['50%']:.3f}\")\n",
    "    print(f\"   Std Dev: {conf_stats['std']:.3f}\")\n",
    "    print(f\"   Min: {conf_stats['min']:.3f}\")\n",
    "    print(f\"   Max: {conf_stats['max']:.3f}\")\n",
    "    \n",
    "    # Confidence bins analysis\n",
    "    confidence_bins = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    df['confidence_bin'] = pd.cut(df['confidence'], bins=confidence_bins, include_lowest=True)\n",
    "    \n",
    "    confidence_analysis = df.groupby('confidence_bin').agg({\n",
    "        'correct': ['mean', 'count'],\n",
    "        'confidence': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    confidence_analysis.columns = ['accuracy', 'count', 'avg_confidence']\n",
    "    \n",
    "    print(f\"\\nüéØ Performance by Confidence Level:\")\n",
    "    for bin_name, row in confidence_analysis.iterrows():\n",
    "        if row['count'] > 0:\n",
    "            print(f\"   {str(bin_name):15s}: {row['accuracy']:.1%} accuracy ({int(row['count']):4d} predictions)\")\n",
    "    \n",
    "    # Find optimal confidence threshold\n",
    "    thresholds = np.arange(0.5, 1.0, 0.05)\n",
    "    threshold_analysis = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        high_conf_preds = df[df['confidence'] >= threshold]\n",
    "        if len(high_conf_preds) > 10:\n",
    "            accuracy = high_conf_preds['correct'].mean()\n",
    "            count = len(high_conf_preds)\n",
    "            coverage = count / len(df)\n",
    "            improvement = accuracy - df['correct'].mean()\n",
    "            \n",
    "            threshold_analysis.append({\n",
    "                'threshold': threshold,\n",
    "                'accuracy': accuracy,\n",
    "                'count': count,\n",
    "                'coverage': coverage,\n",
    "                'improvement': improvement\n",
    "            })\n",
    "    \n",
    "    if threshold_analysis:\n",
    "        threshold_df = pd.DataFrame(threshold_analysis)\n",
    "        # Find best threshold (balance accuracy improvement and coverage)\n",
    "        threshold_df['score'] = threshold_df['improvement'] * np.sqrt(threshold_df['coverage'])\n",
    "        best_threshold = threshold_df.loc[threshold_df['score'].idxmax()]\n",
    "        \n",
    "        print(f\"\\nüèÜ Optimal Confidence Threshold Analysis:\")\n",
    "        print(f\"   Recommended Threshold: {best_threshold['threshold']:.2f}\")\n",
    "        print(f\"   Accuracy at Threshold: {best_threshold['accuracy']:.1%}\")\n",
    "        print(f\"   Predictions Remaining: {best_threshold['count']:,} ({best_threshold['coverage']:.1%} coverage)\")\n",
    "        print(f\"   Accuracy Improvement: +{best_threshold['improvement']:.1%}\")\n",
    "        \n",
    "        return threshold_df, best_threshold\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "threshold_analysis, best_threshold = analyze_confidence_patterns(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Trading Strategy Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_trading_strategies(df, market_data=None):\n",
    "    \"\"\"\n",
    "    Simulate simple trading strategies based on predictions\n",
    "    \"\"\"\n",
    "    print(\"üí∞ TRADING STRATEGY SIMULATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    strategies = {}\n",
    "    \n",
    "    # Strategy 1: Trade all predictions\n",
    "    df['strategy_return'] = np.where(\n",
    "        df['correct'], \n",
    "        0.01,  # 1% return for correct prediction\n",
    "        -0.01  # -1% return for incorrect prediction\n",
    "    )\n",
    "    \n",
    "    total_return_all = df['strategy_return'].sum()\n",
    "    win_rate_all = df['correct'].mean()\n",
    "    total_trades_all = len(df)\n",
    "    \n",
    "    strategies['all_predictions'] = {\n",
    "        'name': 'Trade All Predictions',\n",
    "        'total_return': total_return_all,\n",
    "        'win_rate': win_rate_all,\n",
    "        'total_trades': total_trades_all,\n",
    "        'avg_return_per_trade': total_return_all / total_trades_all if total_trades_all > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # Strategy 2: Trade only high confidence predictions\n",
    "    high_conf_mask = df['confidence'] >= 0.7\n",
    "    high_conf_df = df[high_conf_mask]\n",
    "    \n",
    "    if len(high_conf_df) > 0:\n",
    "        total_return_hc = high_conf_df['strategy_return'].sum()\n",
    "        win_rate_hc = high_conf_df['correct'].mean()\n",
    "        total_trades_hc = len(high_conf_df)\n",
    "        \n",
    "        strategies['high_confidence'] = {\n",
    "            'name': 'High Confidence Only (‚â•0.7)',\n",
    "            'total_return': total_return_hc,\n",
    "            'win_rate': win_rate_hc,\n",
    "            'total_trades': total_trades_hc,\n",
    "            'avg_return_per_trade': total_return_hc / total_trades_hc\n",
    "        }\n",
    "    \n",
    "    # Strategy 3: Trade only best performing stocks\n",
    "    if 'stock_performance' in globals():\n",
    "        best_stocks = stock_performance[stock_performance['accuracy'] > 0.55]['ticker'].tolist()\n",
    "        best_stocks_df = df[df['ticker'].isin(best_stocks)]\n",
    "        \n",
    "        if len(best_stocks_df) > 0:\n",
    "            total_return_bs = best_stocks_df['strategy_return'].sum()\n",
    "            win_rate_bs = best_stocks_df['correct'].mean()\n",
    "            total_trades_bs = len(best_stocks_df)\n",
    "            \n",
    "            strategies['best_stocks'] = {\n",
    "                'name': f'Best Stocks Only (>55% accuracy)',\n",
    "                'total_return': total_return_bs,\n",
    "                'win_rate': win_rate_bs,\n",
    "                'total_trades': total_trades_bs,\n",
    "                'avg_return_per_trade': total_return_bs / total_trades_bs\n",
    "            }\n",
    "    \n",
    "    # Strategy 4: Combined (High confidence + Best stocks)\n",
    "    if 'best_stocks' in strategies:\n",
    "        combined_mask = (df['confidence'] >= 0.7) & (df['ticker'].isin(best_stocks))\n",
    "        combined_df = df[combined_mask]\n",
    "        \n",
    "        if len(combined_df) > 0:\n",
    "            total_return_cb = combined_df['strategy_return'].sum()\n",
    "            win_rate_cb = combined_df['correct'].mean()\n",
    "            total_trades_cb = len(combined_df)\n",
    "            \n",
    "            strategies['combined'] = {\n",
    "                'name': 'Combined (High Conf + Best Stocks)',\n",
    "                'total_return': total_return_cb,\n",
    "                'win_rate': win_rate_cb,\n",
    "                'total_trades': total_trades_cb,\n",
    "                'avg_return_per_trade': total_return_cb / total_trades_cb\n",
    "            }\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nüìä Strategy Comparison (Simplified Returns):\")\n",
    "    print(f\"{'Strategy':<35} {'Return':<10} {'Win Rate':<10} {'Trades':<8} {'Avg/Trade':<10}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for strategy in strategies.values():\n",
    "        print(f\"{strategy['name']:<35} {strategy['total_return']:>+7.1%} {strategy['win_rate']:>8.1%} {strategy['total_trades']:>6d} {strategy['avg_return_per_trade']:>+8.2%}\")\n",
    "    \n",
    "    # Risk metrics\n",
    "    print(f\"\\nüìà Risk Metrics:\")\n",
    "    \n",
    "    for name, strategy in strategies.items():\n",
    "        if name == 'all_predictions':\n",
    "            strategy_df = df\n",
    "        elif name == 'high_confidence':\n",
    "            strategy_df = df[df['confidence'] >= 0.7]\n",
    "        elif name == 'best_stocks':\n",
    "            strategy_df = df[df['ticker'].isin(best_stocks)]\n",
    "        elif name == 'combined':\n",
    "            strategy_df = df[(df['confidence'] >= 0.7) & (df['ticker'].isin(best_stocks))]\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        if len(strategy_df) > 1:\n",
    "            returns = strategy_df['strategy_return']\n",
    "            volatility = returns.std()\n",
    "            sharpe = returns.mean() / volatility if volatility > 0 else 0\n",
    "            max_loss_streak = 0\n",
    "            current_streak = 0\n",
    "            \n",
    "            # Calculate maximum loss streak\n",
    "            for ret in returns:\n",
    "                if ret < 0:\n",
    "                    current_streak += 1\n",
    "                    max_loss_streak = max(max_loss_streak, current_streak)\n",
    "                else:\n",
    "                    current_streak = 0\n",
    "            \n",
    "            print(f\"   {strategy['name']:<35}: Volatility={volatility:.3f}, Sharpe={sharpe:.2f}, Max Loss Streak={max_loss_streak}\")\n",
    "    \n",
    "    return strategies\n",
    "\n",
    "trading_strategies = simulate_trading_strategies(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Analysis: Market Conditions Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_market_conditions_impact(df, market_data=None):\n",
    "    \"\"\"\n",
    "    Analyze how different market conditions affect prediction accuracy\n",
    "    \"\"\"\n",
    "    print(\"üìä MARKET CONDITIONS IMPACT ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if market_data is None or len(market_data) == 0:\n",
    "        print(\"‚ö†Ô∏è  No market data available for market conditions analysis\")\n",
    "        print(\"üí° To enable this analysis, ensure market data is downloaded successfully\")\n",
    "        return\n",
    "    \n",
    "    # Analyze performance during different volatility regimes\n",
    "    # Get SPY data as market proxy\n",
    "    try:\n",
    "        spy_data = yf.Ticker('SPY').history(start=df['prediction_date'].min(), \n",
    "                                          end=df['prediction_date'].max())\n",
    "        \n",
    "        if not spy_data.empty:\n",
    "            # Calculate daily market returns and volatility\n",
    "            spy_data['returns'] = spy_data['Close'].pct_change()\n",
    "            spy_data['volatility'] = spy_data['returns'].rolling(window=10).std()\n",
    "            \n",
    "            # Add market regime to predictions\n",
    "            df_with_market = df.copy()\n",
    "            df_with_market['market_return'] = df_with_market['prediction_date'].map(\n",
    "                lambda x: spy_data.loc[spy_data.index.date == x.date(), 'returns'].iloc[0] \n",
    "                if x.date() in spy_data.index.date else np.nan\n",
    "            )\n",
    "            \n",
    "            df_with_market['market_volatility'] = df_with_market['prediction_date'].map(\n",
    "                lambda x: spy_data.loc[spy_data.index.date == x.date(), 'volatility'].iloc[0] \n",
    "                if x.date() in spy_data.index.date else np.nan\n",
    "            )\n",
    "            \n",
    "            # Remove NaN values\n",
    "            df_with_market = df_with_market.dropna(subset=['market_return', 'market_volatility'])\n",
    "            \n",
    "            if len(df_with_market) > 0:\n",
    "                # Classify market conditions\n",
    "                vol_high_threshold = df_with_market['market_volatility'].quantile(0.75)\n",
    "                vol_low_threshold = df_with_market['market_volatility'].quantile(0.25)\n",
    "                \n",
    "                def classify_volatility(vol):\n",
    "                    if vol > vol_high_threshold:\n",
    "                        return 'High Volatility'\n",
    "                    elif vol < vol_low_threshold:\n",
    "                        return 'Low Volatility'\n",
    "                    else:\n",
    "                        return 'Medium Volatility'\n",
    "                \n",
    "                def classify_market_direction(ret):\n",
    "                    if ret > 0.005:  # >0.5% up\n",
    "                        return 'Strong Up'\n",
    "                    elif ret > 0:\n",
    "                        return 'Weak Up'\n",
    "                    elif ret > -0.005:  # >-0.5% down\n",
    "                        return 'Weak Down'\n",
    "                    else:\n",
    "                        return 'Strong Down'\n",
    "                \n",
    "                df_with_market['volatility_regime'] = df_with_market['market_volatility'].apply(classify_volatility)\n",
    "                df_with_market['market_regime'] = df_with_market['market_return'].apply(classify_market_direction)\n",
    "                \n",
    "                # Performance by volatility regime\n",
    "                vol_performance = df_with_market.groupby('volatility_regime')['correct'].agg(['mean', 'count'])\n",
    "                print(f\"\\nüìà Performance by Volatility Regime:\")\n",
    "                for regime, row in vol_performance.iterrows():\n",
    "                    print(f\"   {regime:18s}: {row['mean']:.1%} accuracy ({int(row['count']):3d} predictions)\")\n",
    "                \n",
    "                # Performance by market direction\n",
    "                market_performance = df_with_market.groupby('market_regime')['correct'].agg(['mean', 'count'])\n",
    "                print(f\"\\nüìä Performance by Market Regime:\")\n",
    "                for regime, row in market_performance.iterrows():\n",
    "                    print(f\"   {regime:12s}: {row['mean']:.1%} accuracy ({int(row['count']):3d} predictions)\")\n",
    "                    \n",
    "                return df_with_market\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error in market conditions analysis: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "market_analysis = analyze_market_conditions_impact(predictions_df, market_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Action Items and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_actionable_recommendations(overall_metrics, stock_performance, threshold_analysis, trading_strategies):\n",
    "    \"\"\"\n",
    "    Generate specific, actionable recommendations based on analysis\n",
    "    \"\"\"\n",
    "    print(\"üéØ ACTIONABLE RECOMMENDATIONS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    # Overall performance recommendations\n",
    "    if overall_metrics['is_significant'] and overall_metrics['overall_accuracy'] > 0.55:\n",
    "        recommendations.append({\n",
    "            'priority': 'HIGH',\n",
    "            'category': 'Model Deployment',\n",
    "            'action': f\"Deploy model for live trading - shows {overall_metrics['overall_accuracy']:.1%} accuracy with statistical significance\",\n",
    "            'details': [\n",
    "                \"Set up automated daily prediction pipeline\",\n",
    "                \"Implement position sizing based on confidence scores\",\n",
    "                \"Monitor performance decay weekly\"\n",
    "            ]\n",
    "        })\n",
    "    elif overall_metrics['overall_accuracy'] > 0.52:\n",
    "        recommendations.append({\n",
    "            'priority': 'MEDIUM',\n",
    "            'category': 'Model Improvement',\n",
    "            'action': f\"Model shows promise ({overall_metrics['overall_accuracy']:.1%}) but needs optimization before deployment\",\n",
    "            'details': [\n",
    "                \"Focus on high-confidence predictions only\",\n",
    "                \"Experiment with ensemble methods\",\n",
    "                \"Consider additional feature engineering\"\n",
    "            ]\n",
    "        })\n",
    "    else:\n",
    "        recommendations.append({\n",
    "            'priority': 'HIGH',\n",
    "            'category': 'Model Redesign',\n",
    "            'action': f\"Model performance ({overall_metrics['overall_accuracy']:.1%}) requires significant improvement\",\n",
    "            'details': [\n",
    "                \"Gather more training data\",\n",
    "                \"Try different prediction targets (volatility, relative performance)\",\n",
    "                \"Consider market regime awareness\",\n",
    "                \"Add macroeconomic features\"\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    # Stock selection recommendations\n",
    "    poor_performers = stock_performance[stock_performance['accuracy'] < 0.45]\n",
    "    if len(poor_performers) > 0:\n",
    "        recommendations.append({\n",
    "            'priority': 'HIGH',\n",
    "            'category': 'Stock Selection',\n",
    "            'action': f\"Exclude {len(poor_performers)} poor-performing stocks from trading universe\",\n",
    "            'details': [\n",
    "                f\"Blacklist: {', '.join(poor_performers['ticker'].tolist()[:10])}\",\n",
    "                \"Focus on stocks with >55% accuracy\",\n",
    "                \"Investigate sector-specific patterns\"\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    best_performers = stock_performance[stock_performance['accuracy'] > 0.6]\n",
    "    if len(best_performers) > 0:\n",
    "        recommendations.append({\n",
    "            'priority': 'MEDIUM',\n",
    "            'category': 'Portfolio Concentration',\n",
    "            'action': f\"Consider concentrating on {len(best_performers)} top-performing stocks\",\n",
    "            'details': [\n",
    "                f\"Focus on: {', '.join(best_performers['ticker'].tolist()[:10])}\",\n",
    "                \"Allocate more capital to high-accuracy stocks\",\n",
    "                \"Monitor if performance persists out-of-sample\"\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    # Confidence threshold recommendations\n",
    "    if threshold_analysis is not None:\n",
    "        best_threshold = threshold_analysis.loc[threshold_analysis['score'].idxmax()]\n",
    "        recommendations.append({\n",
    "            'priority': 'HIGH',\n",
    "            'category': 'Risk Management',\n",
    "            'action': f\"Implement confidence threshold of {best_threshold['threshold']:.2f} for trade filtering\",\n",
    "            'details': [\n",
    "                f\"Expected accuracy: {best_threshold['accuracy']:.1%} (+{best_threshold['improvement']:.1%} improvement)\",\n",
    "                f\"Trade coverage: {best_threshold['coverage']:.1%} of all signals\",\n",
    "                \"Use confidence scores for position sizing\"\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    # Trading strategy recommendations\n",
    "    if trading_strategies:\n",
    "        best_strategy = max(trading_strategies.values(), key=lambda x: x['total_return'])\n",
    "        recommendations.append({\n",
    "            'priority': 'MEDIUM',\n",
    "            'category': 'Trading Strategy',\n",
    "            'action': f\"Implement '{best_strategy['name']}' strategy (best backtested performance)\",\n",
    "            'details': [\n",
    "                f\"Expected return: {best_strategy['total_return']:+.1%} over testing period\",\n",
    "                f\"Win rate: {best_strategy['win_rate']:.1%}\",\n",
    "                f\"Number of trades: {best_strategy['total_trades']}\"\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    # Technical recommendations\n",
    "    recommendations.extend([\n",
    "        {\n",
    "            'priority': 'HIGH',\n",
    "            'category': 'Monitoring',\n",
    "            'action': 'Set up comprehensive monitoring and alerting system',\n",
    "            'details': [\n",
    "                \"Daily accuracy tracking\",\n",
    "                \"Model performance decay alerts\",\n",
    "                \"Data quality monitoring\",\n",
    "                \"Exception handling and logging\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'priority': 'MEDIUM',\n",
    "            'category': 'Model Maintenance', \n",
    "            'action': 'Establish regular model retraining schedule',\n",
    "            'details': [\n",
    "                \"Weekly performance review\",\n",
    "                \"Monthly model retraining\",\n",
    "                \"Quarterly feature engineering review\",\n",
    "                \"Document model version changes\"\n",
    "            ]\n",
    "        }\n",
    "    ])\n",
    "    \n",
    "    # Display recommendations\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        priority_emoji = \"üî¥\" if rec['priority'] == 'HIGH' else \"üü°\" if rec['priority'] == 'MEDIUM' else \"üü¢\"\n",
    "        print(f\"\\n{priority_emoji} {rec['priority']} PRIORITY: {rec['category']}\")\n",
    "        print(f\"   Action: {rec['action']}\")\n",
    "        print(f\"   Details:\")\n",
    "        for detail in rec['details']:\n",
    "            print(f\"     ‚Ä¢ {detail}\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "recommendations = generate_actionable_recommendations(\n",
    "    overall_metrics, stock_performance, threshold_analysis, trading_strategies\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_analysis_results():\n",
    "    \"\"\"\n",
    "    Export analysis results for future reference\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create results directory\n",
    "    results_dir = Path(\"analysis_results\")\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Export stock performance\n",
    "    stock_performance.to_csv(results_dir / f\"stock_performance_{timestamp}.csv\", index=False)\n",
    "    \n",
    "    # Export daily performance\n",
    "    if 'daily_perf' in globals():\n",
    "        daily_perf.to_csv(results_dir / f\"daily_performance_{timestamp}.csv\", index=False)\n",
    "    \n",
    "    # Export summary report\n",
    "    summary_report = {\n",
    "        'analysis_date': datetime.now().isoformat(),\n",
    "        'data_period': {\n",
    "            'start_date': predictions_df['prediction_date'].min().isoformat(),\n",
    "            'end_date': predictions_df['prediction_date'].max().isoformat(),\n",
    "            'total_days': (predictions_df['prediction_date'].max() - predictions_df['prediction_date'].min()).days\n",
    "        },\n",
    "        'overall_metrics': overall_metrics,\n",
    "        'top_performing_stocks': stock_performance.head(10).to_dict('records'),\n",
    "        'poor_performing_stocks': stock_performance.tail(5).to_dict('records'),\n",
    "        'confidence_analysis': {\n",
    "            'average_confidence': float(predictions_df['confidence'].mean()),\n",
    "            'confidence_std': float(predictions_df['confidence'].std()),\n",
    "            'high_confidence_count': int((predictions_df['confidence'] >= 0.7).sum()),\n",
    "            'high_confidence_accuracy': float(predictions_df[predictions_df['confidence'] >= 0.7]['correct'].mean()) if (predictions_df['confidence'] >= 0.7).sum() > 0 else 0\n",
    "        },\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "    \n",
    "    with open(results_dir / f\"analysis_summary_{timestamp}.json\", 'w') as f:\n",
    "        json.dump(summary_report, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\nüíæ Analysis results exported to: {results_dir}\")\n",
    "    print(f\"   üìä Stock performance: stock_performance_{timestamp}.csv\")\n",
    "    print(f\"   üìÖ Daily performance: daily_performance_{timestamp}.csv\")\n",
    "    print(f\"   üìã Summary report: analysis_summary_{timestamp}.json\")\n",
    "    \n",
    "    return results_dir\n",
    "\n",
    "results_dir = export_analysis_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a comprehensive analysis of your stock prediction model's performance. Here's what we've covered:\n",
    "\n",
    "### Key Analysis Areas:\n",
    "1. **üìä Overall Performance**: Statistical significance, accuracy metrics, classification performance\n",
    "2. **üìà Stock-by-Stock Analysis**: Individual stock performance, best/worst performers, exclusion recommendations\n",
    "3. **üìÖ Temporal Patterns**: Daily performance trends, day-of-week effects, performance decay analysis\n",
    "4. **üéØ Confidence Analysis**: Optimal thresholds, calibration assessment, filtering strategies\n",
    "5. **üí∞ Trading Simulation**: Strategy backtesting, risk metrics, return projections\n",
    "6. **üåä Market Conditions**: Performance under different volatility and market regimes\n",
    "7. **üéØ Actionable Recommendations**: Prioritized action items for model improvement and deployment\n",
    "\n",
    "### Next Steps:\n",
    "1. **Review the recommendations** generated in section 10\n",
    "2. **Implement the suggested improvements** based on your analysis results\n",
    "3. **Set up monitoring** using the deployment guide (README_DEPLOYMENT.md)\n",
    "4. **Re-run this analysis weekly** to track model performance over time\n",
    "5. **Adjust your trading strategy** based on the confidence and stock-specific insights\n",
    "\n",
    "### Files Generated:\n",
    "- Stock performance CSV for detailed stock-level analysis\n",
    "- Daily performance CSV for temporal trend analysis\n",
    "- Summary JSON with key metrics and recommendations\n",
    "\n",
    "**Remember**: Past performance doesn't guarantee future results. Always use proper risk management and consider this analysis as one input in your trading decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}