{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction Performance Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis of your stock prediction model's performance across different stocks, time periods, and confidence levels.\n",
    "\n",
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"📊 Stock Prediction Analysis Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Prediction Data\n",
    "\n",
    "Load prediction results from your deployed service or local experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prediction_files(prediction_dir=\"./predictions\"):\n",
    "    \"\"\"\n",
    "    Load all prediction files from directory\n",
    "    \"\"\"\n",
    "    prediction_files = glob.glob(f\"{prediction_dir}/predictions_*.json\")\n",
    "    \n",
    "    if not prediction_files:\n",
    "        print(f\"❌ No prediction files found in {prediction_dir}\")\n",
    "        print(\"💡 Tip: If running from local experiments, check if files are in current directory\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    for file_path in sorted(prediction_files):\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                predictions = json.load(f)\n",
    "            \n",
    "            # Convert to DataFrame and add file info\n",
    "            df = pd.DataFrame(predictions)\n",
    "            df['source_file'] = file_path\n",
    "            all_predictions.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Error loading {file_path}: {e}\")\n",
    "    \n",
    "    if all_predictions:\n",
    "        combined_df = pd.concat(all_predictions, ignore_index=True)\n",
    "        print(f\"✅ Loaded {len(combined_df)} predictions from {len(prediction_files)} files\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_sample_results():\n",
    "    \"\"\"\n",
    "    Create sample prediction results for demonstration\n",
    "    Replace this with your actual prediction loading\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'JPM', 'V', 'PG']\n",
    "    dates = pd.date_range('2024-01-01', '2024-03-01', freq='B')  # Business days only\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for date in dates:\n",
    "        for ticker in tickers:\n",
    "            # Simulate predictions with realistic patterns\n",
    "            base_accuracy = np.random.uniform(0.45, 0.65)  # Stock-specific performance\n",
    "            confidence = np.random.uniform(0.5, 0.95)\n",
    "            \n",
    "            # Higher confidence should correlate with better accuracy\n",
    "            if confidence > 0.8:\n",
    "                prediction_correct = np.random.random() < (base_accuracy + 0.1)\n",
    "            elif confidence > 0.6:\n",
    "                prediction_correct = np.random.random() < base_accuracy\n",
    "            else:\n",
    "                prediction_correct = np.random.random() < (base_accuracy - 0.05)\n",
    "            \n",
    "            prediction = np.random.choice([0, 1])\n",
    "            actual = prediction if prediction_correct else (1 - prediction)\n",
    "            \n",
    "            predictions.append({\n",
    "                'ticker': ticker,\n",
    "                'prediction_date': date.strftime('%Y-%m-%d'),\n",
    "                'target_date': (date + timedelta(days=1)).strftime('%Y-%m-%d'),\n",
    "                'prediction': prediction,\n",
    "                'actual': actual,\n",
    "                'confidence': confidence,\n",
    "                'correct': prediction == actual,\n",
    "                'latest_close': np.random.uniform(100, 300)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "# Try to load actual prediction files, fall back to sample data\n",
    "predictions_df = load_prediction_files()\n",
    "\n",
    "if predictions_df.empty:\n",
    "    print(\"📝 Using sample data for demonstration\")\n",
    "    predictions_df = load_sample_results()\n",
    "\n",
    "# Convert date columns\n",
    "predictions_df['prediction_date'] = pd.to_datetime(predictions_df['prediction_date'])\n",
    "predictions_df['target_date'] = pd.to_datetime(predictions_df['target_date'])\n",
    "\n",
    "print(f\"\\n📊 Dataset Overview:\")\n",
    "print(f\"   Total Predictions: {len(predictions_df):,}\")\n",
    "print(f\"   Date Range: {predictions_df['prediction_date'].min().date()} to {predictions_df['prediction_date'].max().date()}\")\n",
    "print(f\"   Unique Stocks: {predictions_df['ticker'].nunique()}\")\n",
    "print(f\"   Overall Accuracy: {predictions_df['correct'].mean():.1%}\")\n",
    "\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Actual Market Data for Verification\n",
    "\n",
    "Download actual stock prices to verify prediction accuracy and calculate real returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_actual_market_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Download actual market data to verify predictions\n",
    "    \"\"\"\n",
    "    print(f\"📥 Downloading actual market data for {len(tickers)} stocks...\")\n",
    "    \n",
    "    market_data = {}\n",
    "    failed_tickers = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            hist = stock.history(start=start_date, end=end_date)\n",
    "            \n",
    "            if not hist.empty:\n",
    "                market_data[ticker] = hist\n",
    "                print(f\"✓ {ticker}: {len(hist)} days\")\n",
    "            else:\n",
    "                failed_tickers.append(ticker)\n",
    "                \n",
    "        except Exception as e:\n",
    "            failed_tickers.append(ticker)\n",
    "            print(f\"✗ {ticker}: {e}\")\n",
    "    \n",
    "    print(f\"\\n✅ Downloaded data for {len(market_data)}/{len(tickers)} stocks\")\n",
    "    if failed_tickers:\n",
    "        print(f\"❌ Failed: {failed_tickers}\")\n",
    "    \n",
    "    return market_data\n",
    "\n",
    "def verify_predictions_with_actual_data(predictions_df, market_data):\n",
    "    \"\"\"\n",
    "    Verify predictions against actual market data\n",
    "    \"\"\"\n",
    "    verified_predictions = []\n",
    "    \n",
    "    for _, row in predictions_df.iterrows():\n",
    "        ticker = row['ticker']\n",
    "        target_date = row['target_date']\n",
    "        \n",
    "        if ticker in market_data:\n",
    "            stock_data = market_data[ticker]\n",
    "            \n",
    "            # Find the target trading day (handle weekends/holidays)\n",
    "            target_dates = pd.date_range(target_date, target_date + timedelta(days=3), freq='B')\n",
    "            \n",
    "            for check_date in target_dates:\n",
    "                if check_date.date() in stock_data.index.date:\n",
    "                    day_data = stock_data.loc[stock_data.index.date == check_date.date()].iloc[0]\n",
    "                    \n",
    "                    # Calculate actual direction and return\n",
    "                    actual_direction = 1 if day_data['Close'] > day_data['Open'] else 0\n",
    "                    actual_return = (day_data['Close'] - day_data['Open']) / day_data['Open']\n",
    "                    \n",
    "                    # Update prediction record\n",
    "                    verified_row = row.copy()\n",
    "                    verified_row['actual_verified'] = actual_direction\n",
    "                    verified_row['actual_return'] = actual_return\n",
    "                    verified_row['correct_verified'] = (row['prediction'] == actual_direction)\n",
    "                    verified_row['actual_open'] = day_data['Open']\n",
    "                    verified_row['actual_close'] = day_data['Close']\n",
    "                    verified_row['actual_volume'] = day_data['Volume']\n",
    "                    \n",
    "                    verified_predictions.append(verified_row)\n",
    "                    break\n",
    "    \n",
    "    return pd.DataFrame(verified_predictions)\n",
    "\n",
    "# Download actual market data for verification\n",
    "unique_tickers = predictions_df['ticker'].unique()\n",
    "start_date = predictions_df['target_date'].min() - timedelta(days=5)\n",
    "end_date = predictions_df['target_date'].max() + timedelta(days=5)\n",
    "\n",
    "market_data = download_actual_market_data(unique_tickers, start_date, end_date)\n",
    "\n",
    "# Verify predictions (only if we have real market data)\n",
    "if market_data:\n",
    "    verified_df = verify_predictions_with_actual_data(predictions_df, market_data)\n",
    "    \n",
    "    if not verified_df.empty:\n",
    "        print(f\"\\n🔍 Verification Results:\")\n",
    "        print(f\"   Verified Predictions: {len(verified_df):,}\")\n",
    "        print(f\"   Verified Accuracy: {verified_df['correct_verified'].mean():.1%}\")\n",
    "        \n",
    "        # Use verified data if available\n",
    "        if 'actual_verified' in verified_df.columns:\n",
    "            predictions_df = verified_df\n",
    "            predictions_df['actual'] = predictions_df['actual_verified']\n",
    "            predictions_df['correct'] = predictions_df['correct_verified']\n",
    "else:\n",
    "    print(\"📊 Using original prediction data (no market data verification)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Overall Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_overall_performance(df):\n",
    "    \"\"\"\n",
    "    Comprehensive overall performance analysis\n",
    "    \"\"\"\n",
    "    print(\"🎯 OVERALL MODEL PERFORMANCE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    total_predictions = len(df)\n",
    "    overall_accuracy = df['correct'].mean()\n",
    "    \n",
    "    # Basic metrics\n",
    "    print(f\"📊 Basic Metrics:\")\n",
    "    print(f\"   Total Predictions: {total_predictions:,}\")\n",
    "    print(f\"   Overall Accuracy: {overall_accuracy:.1%}\")\n",
    "    print(f\"   Improvement over Random: {(overall_accuracy - 0.5) * 100:+.1f} percentage points\")\n",
    "    \n",
    "    # Statistical significance\n",
    "    from scipy.stats import binomtest\n",
    "    p_value = binomtest(df['correct'].sum(), total_predictions, 0.5).pvalue\n",
    "    is_significant = p_value < 0.05\n",
    "    \n",
    "    print(f\"\\n📈 Statistical Analysis:\")\n",
    "    print(f\"   P-value vs Random: {p_value:.4f}\")\n",
    "    print(f\"   Statistically Significant: {'✅ YES' if is_significant else '❌ NO'}\")\n",
    "    \n",
    "    # Precision, Recall, F1\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    precision = precision_score(df['actual'], df['prediction'])\n",
    "    recall = recall_score(df['actual'], df['prediction'])\n",
    "    f1 = f1_score(df['actual'], df['prediction'])\n",
    "    \n",
    "    print(f\"\\n🎯 Classification Metrics:\")\n",
    "    print(f\"   Precision: {precision:.3f}\")\n",
    "    print(f\"   Recall: {recall:.3f}\")\n",
    "    print(f\"   F1-Score: {f1:.3f}\")\n",
    "    \n",
    "    # Prediction distribution\n",
    "    up_predictions = (df['prediction'] == 1).sum()\n",
    "    down_predictions = (df['prediction'] == 0).sum()\n",
    "    actual_up = (df['actual'] == 1).sum()\n",
    "    actual_down = (df['actual'] == 0).sum()\n",
    "    \n",
    "    print(f\"\\n📊 Prediction Distribution:\")\n",
    "    print(f\"   Predicted UP: {up_predictions:,} ({up_predictions/total_predictions:.1%})\")\n",
    "    print(f\"   Predicted DOWN: {down_predictions:,} ({down_predictions/total_predictions:.1%})\")\n",
    "    print(f\"   Actual UP: {actual_up:,} ({actual_up/total_predictions:.1%})\")\n",
    "    print(f\"   Actual DOWN: {actual_down:,} ({actual_down/total_predictions:.1%})\")\n",
    "    \n",
    "    # Confidence analysis\n",
    "    avg_confidence = df['confidence'].mean()\n",
    "    high_conf_mask = df['confidence'] >= 0.7\n",
    "    high_conf_accuracy = df[high_conf_mask]['correct'].mean() if high_conf_mask.sum() > 0 else 0\n",
    "    \n",
    "    print(f\"\\n🎯 Confidence Analysis:\")\n",
    "    print(f\"   Average Confidence: {avg_confidence:.3f}\")\n",
    "    print(f\"   High Confidence (≥0.7) Predictions: {high_conf_mask.sum():,} ({high_conf_mask.sum()/total_predictions:.1%})\")\n",
    "    print(f\"   High Confidence Accuracy: {high_conf_accuracy:.1%}\")\n",
    "    \n",
    "    return {\n",
    "        'total_predictions': total_predictions,\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'p_value': p_value,\n",
    "        'is_significant': is_significant,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'high_confidence_accuracy': high_conf_accuracy\n",
    "    }\n",
    "\n",
    "overall_metrics = analyze_overall_performance(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance by Individual Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_stock_performance(df):\n",
    "    \"\"\"\n",
    "    Analyze performance for each individual stock\n",
    "    \"\"\"\n",
    "    stock_metrics = []\n",
    "    \n",
    "    for ticker in df['ticker'].unique():\n",
    "        stock_data = df[df['ticker'] == ticker]\n",
    "        \n",
    "        if len(stock_data) < 5:  # Skip stocks with too few predictions\n",
    "            continue\n",
    "        \n",
    "        accuracy = stock_data['correct'].mean()\n",
    "        total_preds = len(stock_data)\n",
    "        avg_confidence = stock_data['confidence'].mean()\n",
    "        \n",
    "        # Separate accuracy for UP vs DOWN predictions\n",
    "        up_preds = stock_data[stock_data['prediction'] == 1]\n",
    "        down_preds = stock_data[stock_data['prediction'] == 0]\n",
    "        \n",
    "        up_accuracy = up_preds['correct'].mean() if len(up_preds) > 0 else 0\n",
    "        down_accuracy = down_preds['correct'].mean() if len(down_preds) > 0 else 0\n",
    "        \n",
    "        # Prediction bias\n",
    "        up_prediction_rate = (stock_data['prediction'] == 1).mean()\n",
    "        actual_up_rate = (stock_data['actual'] == 1).mean()\n",
    "        prediction_bias = up_prediction_rate - actual_up_rate\n",
    "        \n",
    "        # High confidence performance\n",
    "        high_conf_data = stock_data[stock_data['confidence'] >= 0.7]\n",
    "        high_conf_accuracy = high_conf_data['correct'].mean() if len(high_conf_data) > 0 else accuracy\n",
    "        \n",
    "        stock_metrics.append({\n",
    "            'ticker': ticker,\n",
    "            'accuracy': accuracy,\n",
    "            'total_predictions': total_preds,\n",
    "            'avg_confidence': avg_confidence,\n",
    "            'up_accuracy': up_accuracy,\n",
    "            'down_accuracy': down_accuracy,\n",
    "            'up_prediction_rate': up_prediction_rate,\n",
    "            'actual_up_rate': actual_up_rate,\n",
    "            'prediction_bias': prediction_bias,\n",
    "            'high_conf_accuracy': high_conf_accuracy,\n",
    "            'high_conf_count': len(high_conf_data)\n",
    "        })\n",
    "    \n",
    "    stock_df = pd.DataFrame(stock_metrics).sort_values('accuracy', ascending=False)\n",
    "    \n",
    "    print(\"📈 STOCK-BY-STOCK PERFORMANCE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\n🏆 TOP 10 PERFORMING STOCKS:\")\n",
    "    for i, (_, row) in enumerate(stock_df.head(10).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['ticker']:5s} - {row['accuracy']:.1%} accuracy ({row['total_predictions']:3d} predictions, {row['avg_confidence']:.2f} avg conf)\")\n",
    "    \n",
    "    print(f\"\\n📉 BOTTOM 5 PERFORMING STOCKS:\")\n",
    "    for i, (_, row) in enumerate(stock_df.tail(5).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['ticker']:5s} - {row['accuracy']:.1%} accuracy ({row['total_predictions']:3d} predictions, {row['avg_confidence']:.2f} avg conf)\")\n",
    "    \n",
    "    # Performance categories\n",
    "    excellent = stock_df[stock_df['accuracy'] > 0.65]\n",
    "    good = stock_df[(stock_df['accuracy'] > 0.55) & (stock_df['accuracy'] <= 0.65)]\n",
    "    average = stock_df[(stock_df['accuracy'] > 0.45) & (stock_df['accuracy'] <= 0.55)]\n",
    "    poor = stock_df[stock_df['accuracy'] <= 0.45]\n",
    "    \n",
    "    print(f\"\\n📊 PERFORMANCE CATEGORIES:\")\n",
    "    print(f\"   Excellent (>65%): {len(excellent)} stocks\")\n",
    "    print(f\"   Good (55-65%): {len(good)} stocks\")\n",
    "    print(f\"   Average (45-55%): {len(average)} stocks\")\n",
    "    print(f\"   Poor (<45%): {len(poor)} stocks\")\n",
    "    \n",
    "    if len(poor) > 0:\n",
    "        print(f\"\\n⚠️  Consider excluding poor performers: {', '.join(poor['ticker'].tolist())}\")\n",
    "    \n",
    "    return stock_df\n",
    "\n",
    "stock_performance = analyze_stock_performance(predictions_df)\n",
    "stock_performance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization: Stock Performance Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock Performance Bar Chart\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Sort stocks by accuracy for better visualization\n",
    "stock_sorted = stock_performance.sort_values('accuracy', ascending=True)\n",
    "\n",
    "# Color code based on performance\n",
    "colors = ['red' if x < 0.45 else 'orange' if x < 0.5 else 'lightblue' if x < 0.55 else 'lightgreen' if x < 0.65 else 'green' \n",
    "          for x in stock_sorted['accuracy']]\n",
    "\n",
    "# Create horizontal bar chart\n",
    "bars = plt.barh(range(len(stock_sorted)), stock_sorted['accuracy'], color=colors, alpha=0.7)\n",
    "\n",
    "# Add reference lines\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "plt.axvline(x=0.55, color='blue', linestyle='--', alpha=0.5, label='Good (55%)')\n",
    "plt.axvline(x=0.65, color='green', linestyle='--', alpha=0.5, label='Excellent (65%)')\n",
    "\n",
    "# Customize chart\n",
    "plt.yticks(range(len(stock_sorted)), stock_sorted['ticker'])\n",
    "plt.xlabel('Prediction Accuracy')\n",
    "plt.title('Stock Prediction Accuracy by Ticker\\n(Higher is Better)', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add accuracy labels on bars\n",
    "for i, (bar, accuracy) in enumerate(zip(bars, stock_sorted['accuracy'])):\n",
    "    plt.text(accuracy + 0.005, i, f'{accuracy:.1%}', \n",
    "             va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n📊 Stock Performance Summary:\")\n",
    "print(f\"   Best Performing Stock: {stock_performance.iloc[0]['ticker']} ({stock_performance.iloc[0]['accuracy']:.1%})\")\n",
    "print(f\"   Worst Performing Stock: {stock_performance.iloc[-1]['ticker']} ({stock_performance.iloc[-1]['accuracy']:.1%})\")\n",
    "print(f\"   Average Accuracy Across Stocks: {stock_performance['accuracy'].mean():.1%}\")\n",
    "print(f\"   Standard Deviation: {stock_performance['accuracy'].std():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temporal Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_temporal_performance(df):\n",
    "    \"\"\"\n",
    "    Analyze how performance changes over time\n",
    "    \"\"\"\n",
    "    # Daily performance\n",
    "    daily_performance = df.groupby('prediction_date').agg({\n",
    "        'correct': ['mean', 'count'],\n",
    "        'confidence': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    daily_performance.columns = ['accuracy', 'prediction_count', 'avg_confidence']\n",
    "    daily_performance = daily_performance.reset_index()\n",
    "    \n",
    "    # Weekly performance\n",
    "    df['week'] = df['prediction_date'].dt.isocalendar().week\n",
    "    weekly_performance = df.groupby('week')['correct'].mean().reset_index()\n",
    "    \n",
    "    # Day of week performance\n",
    "    df['day_of_week'] = df['prediction_date'].dt.day_name()\n",
    "    dow_performance = df.groupby('day_of_week')['correct'].agg(['mean', 'count']).round(3)\n",
    "    \n",
    "    print(\"📅 TEMPORAL PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\n📊 Performance by Day of Week:\")\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "    for day in day_order:\n",
    "        if day in dow_performance.index:\n",
    "            row = dow_performance.loc[day]\n",
    "            print(f\"   {day:10s}: {row['mean']:.1%} accuracy ({int(row['count']):3d} predictions)\")\n",
    "    \n",
    "    # Best and worst days\n",
    "    best_days = daily_performance.nlargest(5, 'accuracy')\n",
    "    worst_days = daily_performance.nsmallest(5, 'accuracy')\n",
    "    \n",
    "    print(f\"\\n🏆 Best Performing Days:\")\n",
    "    for _, day in best_days.iterrows():\n",
    "        print(f\"   {day['prediction_date'].strftime('%Y-%m-%d')}: {day['accuracy']:.1%} ({day['prediction_count']} predictions)\")\n",
    "    \n",
    "    print(f\"\\n📉 Worst Performing Days:\")\n",
    "    for _, day in worst_days.iterrows():\n",
    "        print(f\"   {day['prediction_date'].strftime('%Y-%m-%d')}: {day['accuracy']:.1%} ({day['prediction_count']} predictions)\")\n",
    "    \n",
    "    return daily_performance, weekly_performance, dow_performance\n",
    "\n",
    "daily_perf, weekly_perf, dow_perf = analyze_temporal_performance(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temporal performance\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Daily accuracy over time\n",
    "ax1.plot(daily_perf['prediction_date'], daily_perf['accuracy'], marker='o', linewidth=2, markersize=4)\n",
    "ax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "ax1.axhline(y=daily_perf['accuracy'].mean(), color='blue', linestyle='--', alpha=0.7, label=f'Average ({daily_perf[\"accuracy\"].mean():.1%})')\n",
    "ax1.set_title('Daily Prediction Accuracy Over Time')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Day of week performance\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "dow_data = [dow_perf.loc[day, 'mean'] if day in dow_perf.index else 0 for day in day_order]\n",
    "dow_colors = ['lightgreen' if x > 0.5 else 'lightcoral' for x in dow_data]\n",
    "\n",
    "bars = ax2.bar(day_order, dow_data, color=dow_colors, alpha=0.7)\n",
    "ax2.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "ax2.set_title('Accuracy by Day of Week')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add accuracy labels on bars\n",
    "for bar, accuracy in zip(bars, dow_data):\n",
    "    if accuracy > 0:\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "                f'{accuracy:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Confidence vs Accuracy Scatter\n",
    "ax3.scatter(predictions_df['confidence'], predictions_df['correct'], alpha=0.5, s=10)\n",
    "\n",
    "# Add trend line\n",
    "confidence_bins = np.arange(0.5, 1.0, 0.05)\n",
    "bin_centers = []\n",
    "bin_accuracies = []\n",
    "\n",
    "for i in range(len(confidence_bins)-1):\n",
    "    mask = (predictions_df['confidence'] >= confidence_bins[i]) & (predictions_df['confidence'] < confidence_bins[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        bin_centers.append((confidence_bins[i] + confidence_bins[i+1]) / 2)\n",
    "        bin_accuracies.append(predictions_df[mask]['correct'].mean())\n",
    "\n",
    "if bin_centers:\n",
    "    ax3.plot(bin_centers, bin_accuracies, color='red', linewidth=3, marker='o', label='Binned Average')\n",
    "\n",
    "ax3.axhline(y=0.5, color='black', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "ax3.set_xlabel('Prediction Confidence')\n",
    "ax3.set_ylabel('Actual Accuracy (0=Wrong, 1=Correct)')\n",
    "ax3.set_title('Model Calibration: Confidence vs Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prediction count over time\n",
    "ax4.bar(daily_perf['prediction_date'], daily_perf['prediction_count'], alpha=0.7, color='skyblue')\n",
    "ax4.set_title('Number of Predictions Per Day')\n",
    "ax4.set_ylabel('Prediction Count')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confidence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_confidence_patterns(df):\n",
    "    \"\"\"\n",
    "    Detailed analysis of confidence score patterns\n",
    "    \"\"\"\n",
    "    print(\"🎯 CONFIDENCE ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Confidence distribution\n",
    "    conf_stats = df['confidence'].describe()\n",
    "    print(f\"\\n📊 Confidence Distribution:\")\n",
    "    print(f\"   Mean: {conf_stats['mean']:.3f}\")\n",
    "    print(f\"   Median: {conf_stats['50%']:.3f}\")\n",
    "    print(f\"   Std Dev: {conf_stats['std']:.3f}\")\n",
    "    print(f\"   Min: {conf_stats['min']:.3f}\")\n",
    "    print(f\"   Max: {conf_stats['max']:.3f}\")\n",
    "    \n",
    "    # Confidence bins analysis\n",
    "    confidence_bins = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    df['confidence_bin'] = pd.cut(df['confidence'], bins=confidence_bins, include_lowest=True)\n",
    "    \n",
    "    confidence_analysis = df.groupby('confidence_bin').agg({\n",
    "        'correct': ['mean', 'count'],\n",
    "        'confidence': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    confidence_analysis.columns = ['accuracy', 'count', 'avg_confidence']\n",
    "    \n",
    "    print(f\"\\n🎯 Performance by Confidence Level:\")\n",
    "    for bin_name, row in confidence_analysis.iterrows():\n",
    "        if row['count'] > 0:\n",
    "            print(f\"   {str(bin_name):15s}: {row['accuracy']:.1%} accuracy ({int(row['count']):4d} predictions)\")\n",
    "    \n",
    "    # Find optimal confidence threshold\n",
    "    thresholds = np.arange(0.5, 1.0, 0.05)\n",
    "    threshold_analysis = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        high_conf_preds = df[df['confidence'] >= threshold]\n",
    "        if len(high_conf_preds) > 10:\n",
    "            accuracy = high_conf_preds['correct'].mean()\n",
    "            count = len(high_conf_preds)\n",
    "            coverage = count / len(df)\n",
    "            improvement = accuracy - df['correct'].mean()\n",
    "            \n",
    "            threshold_analysis.append({\n",
    "                'threshold': threshold,\n",
    "                'accuracy': accuracy,\n",
    "                'count': count,\n",
    "                'coverage': coverage,\n",
    "                'improvement': improvement\n",
    "            })\n",
    "    \n",
    "    if threshold_analysis:\n",
    "        threshold_df = pd.DataFrame(threshold_analysis)\n",
    "        # Find best threshold (balance accuracy improvement and coverage)\n",
    "        threshold_df['score'] = threshold_df['improvement'] * np.sqrt(threshold_df['coverage'])\n",
    "        best_threshold = threshold_df.loc[threshold_df['score'].idxmax()]\n",
    "        \n",
    "        print(f\"\\n🏆 Optimal Confidence Threshold Analysis:\")\n",
    "        print(f\"   Recommended Threshold: {best_threshold['threshold']:.2f}\")\n",
    "        print(f\"   Accuracy at Threshold: {best_threshold['accuracy']:.1%}\")\n",
    "        print(f\"   Predictions Remaining: {best_threshold['count']:,} ({best_threshold['coverage']:.1%} coverage)\")\n",
    "        print(f\"   Accuracy Improvement: +{best_threshold['improvement']:.1%}\")\n",
    "        \n",
    "        return threshold_df, best_threshold\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "threshold_analysis, best_threshold = analyze_confidence_patterns(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Trading Strategy Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_trading_strategies(df, market_data=None):\n",
    "    \"\"\"\n",
    "    Simulate simple trading strategies based on predictions\n",
    "    \"\"\"\n",
    "    print(\"💰 TRADING STRATEGY SIMULATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    strategies = {}\n",
    "    \n",
    "    # Strategy 1: Trade all predictions\n",
    "    df['strategy_return'] = np.where(\n",
    "        df['correct'], \n",
    "        0.01,  # 1% return for correct prediction\n",
    "        -0.01  # -1% return for incorrect prediction\n",
    "    )\n",
    "    \n",
    "    total_return_all = df['strategy_return'].sum()\n",
    "    win_rate_all = df['correct'].mean()\n",
    "    total_trades_all = len(df)\n",
    "    \n",
    "    strategies['all_predictions'] = {\n",
    "        'name': 'Trade All Predictions',\n",
    "        'total_return': total_return_all,\n",
    "        'win_rate': win_rate_all,\n",
    "        'total_trades': total_trades_all,\n",
    "        'avg_return_per_trade': total_return_all / total_trades_all if total_trades_all > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # Strategy 2: Trade only high confidence predictions\n",
    "    high_conf_mask = df['confidence'] >= 0.7\n",
    "    high_conf_df = df[high_conf_mask]\n",
    "    \n",
    "    if len(high_conf_df) > 0:\n",
    "        total_return_hc = high_conf_df['strategy_return'].sum()\n",
    "        win_rate_hc = high_conf_df['correct'].mean()\n",
    "        total_trades_hc = len(high_conf_df)\n",
    "        \n",
    "        strategies['high_confidence'] = {\n",
    "            'name': 'High Confidence Only (≥0.7)',\n",
    "            'total_return': total_return_hc,\n",
    "            'win_rate': win_rate_hc,\n",
    "            'total_trades': total_trades_hc,\n",
    "            'avg_return_per_trade': total_return_hc / total_trades_hc\n",
    "        }\n",
    "    \n",
    "    # Strategy 3: Trade only best performing stocks\n",
    "    if 'stock_performance' in globals():\n",
    "        best_stocks = stock_performance[stock_performance['accuracy'] > 0.55]['ticker'].tolist()\n",
    "        best_stocks_df = df[df['ticker'].isin(best_stocks)]\n",
    "        \n",
    "        if len(best_stocks_df) > 0:\n",
    "            total_return_bs = best_stocks_df['strategy_return'].sum()\n",
    "            win_rate_bs = best_stocks_df['correct'].mean()\n",
    "            total_trades_bs = len(best_stocks_df)\n",
    "            \n",
    "            strategies['best_stocks'] = {\n",
    "                'name': f'Best Stocks Only (>55% accuracy)',\n",
    "                'total_return': total_return_bs,\n",
    "                'win_rate': win_rate_bs,\n",
    "                'total_trades': total_trades_bs,\n",
    "                'avg_return_per_trade': total_return_bs / total_trades_bs\n",
    "            }\n",
    "    \n",
    "    # Strategy 4: Combined (High confidence + Best stocks)\n",
    "    if 'best_stocks' in strategies:\n",
    "        combined_mask = (df['confidence'] >= 0.7) & (df['ticker'].isin(best_stocks))\n",
    "        combined_df = df[combined_mask]\n",
    "        \n",
    "        if len(combined_df) > 0:\n",
    "            total_return_cb = combined_df['strategy_return'].sum()\n",
    "            win_rate_cb = combined_df['correct'].mean()\n",
    "            total_trades_cb = len(combined_df)\n",
    "            \n",
    "            strategies['combined'] = {\n",
    "                'name': 'Combined (High Conf + Best Stocks)',\n",
    "                'total_return': total_return_cb,\n",
    "                'win_rate': win_rate_cb,\n",
    "                'total_trades': total_trades_cb,\n",
    "                'avg_return_per_trade': total_return_cb / total_trades_cb\n",
    "            }\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n📊 Strategy Comparison (Simplified Returns):\")\n",
    "    print(f\"{'Strategy':<35} {'Return':<10} {'Win Rate':<10} {'Trades':<8} {'Avg/Trade':<10}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for strategy in strategies.values():\n",
    "        print(f\"{strategy['name']:<35} {strategy['total_return']:>+7.1%} {strategy['win_rate']:>8.1%} {strategy['total_trades']:>6d} {strategy['avg_return_per_trade']:>+8.2%}\")\n",
    "    \n",
    "    # Risk metrics\n",
    "    print(f\"\\n📈 Risk Metrics:\")\n",
    "    \n",
    "    for name, strategy in strategies.items():\n",
    "        if name == 'all_predictions':\n",
    "            strategy_df = df\n",
    "        elif name == 'high_confidence':\n",
    "            strategy_df = df[df['confidence'] >= 0.7]\n",
    "        elif name == 'best_stocks':\n",
    "            strategy_df = df[df['ticker'].isin(best_stocks)]\n",
    "        elif name == 'combined':\n",
    "            strategy_df = df[(df['confidence'] >= 0.7) & (df['ticker'].isin(best_stocks))]\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        if len(strategy_df) > 1:\n",
    "            returns = strategy_df['strategy_return']\n",
    "            volatility = returns.std()\n",
    "            sharpe = returns.mean() / volatility if volatility > 0 else 0\n",
    "            max_loss_streak = 0\n",
    "            current_streak = 0\n",
    "            \n",
    "            # Calculate maximum loss streak\n",
    "            for ret in returns:\n",
    "                if ret < 0:\n",
    "                    current_streak += 1\n",
    "                    max_loss_streak = max(max_loss_streak, current_streak)\n",
    "                else:\n",
    "                    current_streak = 0\n",
    "            \n",
    "            print(f\"   {strategy['name']:<35}: Volatility={volatility:.3f}, Sharpe={sharpe:.2f}, Max Loss Streak={max_loss_streak}\")\n",
    "    \n",
    "    return strategies\n",
    "\n",
    "trading_strategies = simulate_trading_strategies(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Analysis: Market Conditions Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_market_conditions_impact(df, market_data=None):\n",
    "    \"\"\"\n",
    "    Analyze how different market conditions affect prediction accuracy\n",
    "    \"\"\"\n",
    "    print(\"📊 MARKET CONDITIONS IMPACT ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if market_data is None or len(market_data) == 0:\n",
    "        print(\"⚠️  No market data available for market conditions analysis\")\n",
    "        print(\"💡 To enable this analysis, ensure market data is downloaded successfully\")\n",
    "        return\n",
    "    \n",
    "    # Analyze performance during different volatility regimes\n",
    "    # Get SPY data as market proxy\n",
    "    try:\n",
    "        spy_data = yf.Ticker('SPY').history(start=df['prediction_date'].min(), \n",
    "                                          end=df['prediction_date'].max())\n",
    "        \n",
    "        if not spy_data.empty:\n",
    "            # Calculate daily market returns and volatility\n",
    "            spy_data['returns'] = spy_data['Close'].pct_change()\n",
    "            spy_data['volatility'] = spy_data['returns'].rolling(window=10).std()\n",
    "            \n",
    "            # Add market regime to predictions\n",
    "            df_with_market = df.copy()\n",
    "            df_with_market['market_return'] = df_with_market['prediction_date'].map(\n",
    "                lambda x: spy_data.loc[spy_data.index.date == x.date(), 'returns'].iloc[0] \n",
    "                if x.date() in spy_data.index.date else np.nan\n",
    "            )\n",
    "            \n",
    "            df_with_market['market_volatility'] = df_with_market['prediction_date'].map(\n",
    "                lambda x: spy_data.loc[spy_data.index.date == x.date(), 'volatility'].iloc[0] \n",
    "                if x.date() in spy_data.index.date else np.nan\n",
    "            )\n",
    "            \n",
    "            # Remove NaN values\n",
    "            df_with_market = df_with_market.dropna(subset=['market_return', 'market_volatility'])\n",
    "            \n",
    "            if len(df_with_market) > 0:\n",
    "                # Classify market conditions\n",
    "                vol_high_threshold = df_with_market['market_volatility'].quantile(0.75)\n",
    "                vol_low_threshold = df_with_market['market_volatility'].quantile(0.25)\n",
    "                \n",
    "                def classify_volatility(vol):\n",
    "                    if vol > vol_high_threshold:\n",
    "                        return 'High Volatility'\n",
    "                    elif vol < vol_low_threshold:\n",
    "                        return 'Low Volatility'\n",
    "                    else:\n",
    "                        return 'Medium Volatility'\n",
    "                \n",
    "                def classify_market_direction(ret):\n",
    "                    if ret > 0.005:  # >0.5% up\n",
    "                        return 'Strong Up'\n",
    "                    elif ret > 0:\n",
    "                        return 'Weak Up'\n",
    "                    elif ret > -0.005:  # >-0.5% down\n",
    "                        return 'Weak Down'\n",
    "                    else:\n",
    "                        return 'Strong Down'\n",
    "                \n",
    "                df_with_market['volatility_regime'] = df_with_market['market_volatility'].apply(classify_volatility)\n",
    "                df_with_market['market_regime'] = df_with_market['market_return'].apply(classify_market_direction)\n",
    "                \n",
    "                # Performance by volatility regime\n",
    "                vol_performance = df_with_market.groupby('volatility_regime')['correct'].agg(['mean', 'count'])\n",
    "                print(f\"\\n📈 Performance by Volatility Regime:\")\n",
    "                for regime, row in vol_performance.iterrows():\n",
    "                    print(f\"   {regime:18s}: {row['mean']:.1%} accuracy ({int(row['count']):3d} predictions)\")\n",
    "                \n",
    "                # Performance by market direction\n",
    "                market_performance = df_with_market.groupby('market_regime')['correct'].agg(['mean', 'count'])\n",
    "                print(f\"\\n📊 Performance by Market Regime:\")\n",
    "                for regime, row in market_performance.iterrows():\n",
    "                    print(f\"   {regime:12s}: {row['mean']:.1%} accuracy ({int(row['count']):3d} predictions)\")\n",
    "                    \n",
    "                return df_with_market\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error in market conditions analysis: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "market_analysis = analyze_market_conditions_impact(predictions_df, market_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Action Items and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_actionable_recommendations(overall_metrics, stock_performance, threshold_analysis, trading_strategies):\n",
    "    \"\"\"\n",
    "    Generate specific, actionable recommendations based on analysis\n",
    "    \"\"\"\n",
    "    print(\"🎯 ACTIONABLE RECOMMENDATIONS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    # Overall performance recommendations\n",
    "    if overall_metrics['is_significant'] and overall_metrics['overall_accuracy'] > 0.55:\n",
    "        recommendations.append({\n",
    "            'priority': 'HIGH',\n",
    "            'category': 'Model Deployment',\n",
    "            'action': f\"Deploy model for live trading - shows {overall_metrics['overall_accuracy']:.1%} accuracy with statistical significance\",\n",
    "            'details': [\n",
    "                \"Set up automated daily prediction pipeline\",\n",
    "                \"Implement position sizing based on confidence scores\",\n",
    "                \"Monitor performance decay weekly\"\n",
    "            ]\n",
    "        })\n",
    "    elif overall_metrics['overall_accuracy'] > 0.52:\n",
    "        recommendations.append({\n",
    "            'priority': 'MEDIUM',\n",
    "            'category': 'Model Improvement',\n",
    "            'action': f\"Model shows promise ({overall_metrics['overall_accuracy']:.1%}) but needs optimization before deployment\",\n",
    "            'details': [\n",
    "                \"Focus on high-confidence predictions only\",\n",
    "                \"Experiment with ensemble methods\",\n",
    "                \"Consider additional feature engineering\"\n",
    "            ]\n",
    "        })\n",
    "    else:\n",
    "        recommendations.append({\n",
    "            'priority': 'HIGH',\n",
    "            'category': 'Model Redesign',\n",
    "            'action': f\"Model performance ({overall_metrics['overall_accuracy']:.1%}) requires significant improvement\",\n",
    "            'details': [\n",
    "                \"Gather more training data\",\n",
    "                \"Try different prediction targets (volatility, relative performance)\",\n",
    "                \"Consider market regime awareness\",\n",
    "                \"Add macroeconomic features\"\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    # Stock selection recommendations\n",
    "    poor_performers = stock_performance[stock_performance['accuracy'] < 0.45]\n",
    "    if len(poor_performers) > 0:\n",
    "        recommendations.append({\n",
    "            'priority': 'HIGH',\n",
    "            'category': 'Stock Selection',\n",
    "            'action': f\"Exclude {len(poor_performers)} poor-performing stocks from trading universe\",\n",
    "            'details': [\n",
    "                f\"Blacklist: {', '.join(poor_performers['ticker'].tolist()[:10])}\",\n",
    "                \"Focus on stocks with >55% accuracy\",\n",
    "                \"Investigate sector-specific patterns\"\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    best_performers = stock_performance[stock_performance['accuracy'] > 0.6]\n",
    "    if len(best_performers) > 0:\n",
    "        recommendations.append({\n",
    "            'priority': 'MEDIUM',\n",
    "            'category': 'Portfolio Concentration',\n",
    "            'action': f\"Consider concentrating on {len(best_performers)} top-performing stocks\",\n",
    "            'details': [\n",
    "                f\"Focus on: {', '.join(best_performers['ticker'].tolist()[:10])}\",\n",
    "                \"Allocate more capital to high-accuracy stocks\",\n",
    "                \"Monitor if performance persists out-of-sample\"\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    # Confidence threshold recommendations\n",
    "    if threshold_analysis is not None:\n",
    "        best_threshold = threshold_analysis.loc[threshold_analysis['score'].idxmax()]\n",
    "        recommendations.append({\n",
    "            'priority': 'HIGH',\n",
    "            'category': 'Risk Management',\n",
    "            'action': f\"Implement confidence threshold of {best_threshold['threshold']:.2f} for trade filtering\",\n",
    "            'details': [\n",
    "                f\"Expected accuracy: {best_threshold['accuracy']:.1%} (+{best_threshold['improvement']:.1%} improvement)\",\n",
    "                f\"Trade coverage: {best_threshold['coverage']:.1%} of all signals\",\n",
    "                \"Use confidence scores for position sizing\"\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    # Trading strategy recommendations\n",
    "    if trading_strategies:\n",
    "        best_strategy = max(trading_strategies.values(), key=lambda x: x['total_return'])\n",
    "        recommendations.append({\n",
    "            'priority': 'MEDIUM',\n",
    "            'category': 'Trading Strategy',\n",
    "            'action': f\"Implement '{best_strategy['name']}' strategy (best backtested performance)\",\n",
    "            'details': [\n",
    "                f\"Expected return: {best_strategy['total_return']:+.1%} over testing period\",\n",
    "                f\"Win rate: {best_strategy['win_rate']:.1%}\",\n",
    "                f\"Number of trades: {best_strategy['total_trades']}\"\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    # Technical recommendations\n",
    "    recommendations.extend([\n",
    "        {\n",
    "            'priority': 'HIGH',\n",
    "            'category': 'Monitoring',\n",
    "            'action': 'Set up comprehensive monitoring and alerting system',\n",
    "            'details': [\n",
    "                \"Daily accuracy tracking\",\n",
    "                \"Model performance decay alerts\",\n",
    "                \"Data quality monitoring\",\n",
    "                \"Exception handling and logging\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'priority': 'MEDIUM',\n",
    "            'category': 'Model Maintenance', \n",
    "            'action': 'Establish regular model retraining schedule',\n",
    "            'details': [\n",
    "                \"Weekly performance review\",\n",
    "                \"Monthly model retraining\",\n",
    "                \"Quarterly feature engineering review\",\n",
    "                \"Document model version changes\"\n",
    "            ]\n",
    "        }\n",
    "    ])\n",
    "    \n",
    "    # Display recommendations\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        priority_emoji = \"🔴\" if rec['priority'] == 'HIGH' else \"🟡\" if rec['priority'] == 'MEDIUM' else \"🟢\"\n",
    "        print(f\"\\n{priority_emoji} {rec['priority']} PRIORITY: {rec['category']}\")\n",
    "        print(f\"   Action: {rec['action']}\")\n",
    "        print(f\"   Details:\")\n",
    "        for detail in rec['details']:\n",
    "            print(f\"     • {detail}\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "recommendations = generate_actionable_recommendations(\n",
    "    overall_metrics, stock_performance, threshold_analysis, trading_strategies\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_analysis_results():\n",
    "    \"\"\"\n",
    "    Export analysis results for future reference\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create results directory\n",
    "    results_dir = Path(\"analysis_results\")\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Export stock performance\n",
    "    stock_performance.to_csv(results_dir / f\"stock_performance_{timestamp}.csv\", index=False)\n",
    "    \n",
    "    # Export daily performance\n",
    "    if 'daily_perf' in globals():\n",
    "        daily_perf.to_csv(results_dir / f\"daily_performance_{timestamp}.csv\", index=False)\n",
    "    \n",
    "    # Export summary report\n",
    "    summary_report = {\n",
    "        'analysis_date': datetime.now().isoformat(),\n",
    "        'data_period': {\n",
    "            'start_date': predictions_df['prediction_date'].min().isoformat(),\n",
    "            'end_date': predictions_df['prediction_date'].max().isoformat(),\n",
    "            'total_days': (predictions_df['prediction_date'].max() - predictions_df['prediction_date'].min()).days\n",
    "        },\n",
    "        'overall_metrics': overall_metrics,\n",
    "        'top_performing_stocks': stock_performance.head(10).to_dict('records'),\n",
    "        'poor_performing_stocks': stock_performance.tail(5).to_dict('records'),\n",
    "        'confidence_analysis': {\n",
    "            'average_confidence': float(predictions_df['confidence'].mean()),\n",
    "            'confidence_std': float(predictions_df['confidence'].std()),\n",
    "            'high_confidence_count': int((predictions_df['confidence'] >= 0.7).sum()),\n",
    "            'high_confidence_accuracy': float(predictions_df[predictions_df['confidence'] >= 0.7]['correct'].mean()) if (predictions_df['confidence'] >= 0.7).sum() > 0 else 0\n",
    "        },\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "    \n",
    "    with open(results_dir / f\"analysis_summary_{timestamp}.json\", 'w') as f:\n",
    "        json.dump(summary_report, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\n💾 Analysis results exported to: {results_dir}\")\n",
    "    print(f\"   📊 Stock performance: stock_performance_{timestamp}.csv\")\n",
    "    print(f\"   📅 Daily performance: daily_performance_{timestamp}.csv\")\n",
    "    print(f\"   📋 Summary report: analysis_summary_{timestamp}.json\")\n",
    "    \n",
    "    return results_dir\n",
    "\n",
    "results_dir = export_analysis_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a comprehensive analysis of your stock prediction model's performance. Here's what we've covered:\n",
    "\n",
    "### Key Analysis Areas:\n",
    "1. **📊 Overall Performance**: Statistical significance, accuracy metrics, classification performance\n",
    "2. **📈 Stock-by-Stock Analysis**: Individual stock performance, best/worst performers, exclusion recommendations\n",
    "3. **📅 Temporal Patterns**: Daily performance trends, day-of-week effects, performance decay analysis\n",
    "4. **🎯 Confidence Analysis**: Optimal thresholds, calibration assessment, filtering strategies\n",
    "5. **💰 Trading Simulation**: Strategy backtesting, risk metrics, return projections\n",
    "6. **🌊 Market Conditions**: Performance under different volatility and market regimes\n",
    "7. **🎯 Actionable Recommendations**: Prioritized action items for model improvement and deployment\n",
    "\n",
    "### Next Steps:\n",
    "1. **Review the recommendations** generated in section 10\n",
    "2. **Implement the suggested improvements** based on your analysis results\n",
    "3. **Set up monitoring** using the deployment guide (README_DEPLOYMENT.md)\n",
    "4. **Re-run this analysis weekly** to track model performance over time\n",
    "5. **Adjust your trading strategy** based on the confidence and stock-specific insights\n",
    "\n",
    "### Files Generated:\n",
    "- Stock performance CSV for detailed stock-level analysis\n",
    "- Daily performance CSV for temporal trend analysis\n",
    "- Summary JSON with key metrics and recommendations\n",
    "\n",
    "**Remember**: Past performance doesn't guarantee future results. Always use proper risk management and consider this analysis as one input in your trading decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}